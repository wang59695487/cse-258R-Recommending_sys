{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import csv\n",
    "from sklearn import linear_model\n",
    "from sklearn.decomposition import PCA\n",
    "import scipy\n",
    "import scipy.optimize\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import pandas as pd \n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_regularize(array):\n",
    "    loss = torch.sum(array ** 2.0)\n",
    "    return loss\n",
    "\n",
    "def readCSV(path):\n",
    "  f = open(path, 'rt')\n",
    "  f.readline()\n",
    "  for l in f:\n",
    "    yield l.strip().split(',')\n",
    "    \n",
    "def calc_model_stats(pred,label):\n",
    "    \n",
    "    TP,FP,TN,FN = calc_metrics(pred,label)\n",
    "\n",
    "    # print(\"Stats\")\n",
    "    # print(TP,FP,TN,FN)\n",
    "\n",
    "    # print(\"Predict N: {} ({}%)\".format(TN+FN,(TN+FN)/(TP+TN+FP+FN)))\n",
    "    # print(\"Predict P: {} ({}%)\".format(TP+FP,(TP+FP)/(TP+TN+FP+FN)))\n",
    "\n",
    "    accuracy, TPR, TNR, BER = calc_error_rates(TP, FP, TN, FN)\n",
    "\n",
    "    print(\"Accuracy: {}\".format(accuracy))\n",
    "    # print(\"TPR: {}\".format(TPR))\n",
    "    # print(\"TNR: {}\".format(TNR))\n",
    "    # print(\"BER: {}\".format(BER))\n",
    "    \n",
    "    return\n",
    " \n",
    "def calc_metrics(predictions, labels):\n",
    "    # Calculate True positives, false positives, etc.\n",
    "\n",
    "    TP_ = numpy.logical_and(predictions, labels)\n",
    "    FP_ = numpy.logical_and(predictions, numpy.logical_not(labels))\n",
    "    TN_ = numpy.logical_and(numpy.logical_not(predictions), numpy.logical_not(labels))\n",
    "    FN_ = numpy.logical_and(numpy.logical_not(predictions), labels)\n",
    "\n",
    "    TP=sum(TP_)\n",
    "    FP=sum(FP_)\n",
    "    TN=sum(TN_)\n",
    "    FN=sum(FN_)\n",
    "    \n",
    "    return TP,FP,TN,FN\n",
    "\n",
    "def calc_error_rates(TP, FP, TN, FN):\n",
    "    # Calculate accuracy, TPR, TNR and BER\n",
    "    accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "    TPR = TP/(TP+FN)\n",
    "    TNR = TN/(TN+FP)\n",
    "    BER = 1.0 - (TPR+TNR)/2\n",
    "    \n",
    "    return accuracy, TPR, TNR, BER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF(nn.Module):\n",
    "    itr = 0\n",
    "    \n",
    "    def __init__(self, n_user, n_item, k=1, c_vector=1.0, c_bias=1.0, writer=None):\n",
    "        super(MF, self).__init__()\n",
    "        self.writer = writer\n",
    "        self.k = k\n",
    "        self.n_user = n_user\n",
    "        self.n_item = n_item\n",
    "        self.c_bias = c_bias\n",
    "        self.c_vector = c_vector\n",
    "        \n",
    "        # gammas (users and items)\n",
    "        # self.user = nn.Embedding(n_user, k)\n",
    "        # self.item = nn.Embedding(n_item, k)\n",
    "        \n",
    "        # alpha and betas (users and items)\n",
    "        self.bias_user = nn.Embedding(n_user, 1)\n",
    "        self.bias_item = nn.Embedding(n_item, 1)\n",
    "        self.bias = nn.Parameter(torch.ones(1))\n",
    "    \n",
    "    def forward(self, train_x):\n",
    "        user_id = train_x[:, 0]\n",
    "        item_id = train_x[:, 1]\n",
    "        #vector_user = self.user(user_id)\n",
    "        # vector_item = self.item(item_id)\n",
    "        \n",
    "        # Pull out biases\n",
    "        bias_user = self.bias_user(user_id).squeeze()\n",
    "        bias_item = self.bias_item(item_id).squeeze()\n",
    "        biases = (self.bias + bias_user + bias_item)\n",
    "        \n",
    "        # ui_interaction = torch.sum(vector_user * vector_item, dim=1)\n",
    "        \n",
    "        # Add bias prediction to the interaction prediction\n",
    "        # prediction = ui_interaction + biases\n",
    "        prediction = biases\n",
    "        \n",
    "        return prediction\n",
    "    \n",
    "    def loss(self, prediction, target):\n",
    "        loss_mse = F.mse_loss(prediction, target.squeeze())\n",
    "        \n",
    "        # Add new regularization to the biases\n",
    "        prior_bias_user =  l2_regularize(self.bias_user.weight) * self.c_bias\n",
    "        prior_bias_item = l2_regularize(self.bias_item.weight) * self.c_bias\n",
    "        \n",
    "        # prior_user =  l2_regularize(self.user.weight) * self.c_vector\n",
    "        # prior_item = l2_regularize(self.item.weight) * self.c_vector\n",
    "        \n",
    "        # total = loss_mse + prior_user + prior_item + prior_bias_user + prior_bias_item\n",
    "        total = loss_mse + prior_bias_user + prior_bias_item\n",
    "        for name, var in locals().items():\n",
    "            if type(var) is torch.Tensor and var.nelement() == 1 and self.writer is not None:\n",
    "                self.writer.add_scalar(name, var, self.itr)\n",
    "        return total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## user_id and item_id --> user_idx, item_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Data columns (total 3 columns):\n",
      "userID    200000 non-null object\n",
      "bookID    200000 non-null object\n",
      "rating    200000 non-null int64\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 4.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>bookID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u79354815</td>\n",
       "      <td>b14275065</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u56917948</td>\n",
       "      <td>b82152306</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u97915914</td>\n",
       "      <td>b44882292</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u49688858</td>\n",
       "      <td>b79927466</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u08384938</td>\n",
       "      <td>b05683889</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      userID     bookID  rating\n",
       "0  u79354815  b14275065       4\n",
       "1  u56917948  b82152306       5\n",
       "2  u97915914  b44882292       5\n",
       "3  u49688858  b79927466       5\n",
       "4  u08384938  b05683889       2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../datasets/cse258/assignment1/train_Interactions.csv\")\n",
    "data.info()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reformat Interactions based on (user_idx, book_idx, rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7170 ['b14275065', 'b82152306', 'b44882292']\n",
      "11357 ['u79354815', 'u56917948', 'u97915914']\n"
     ]
    }
   ],
   "source": [
    "book_ids = list(data['bookID'].unique())\n",
    "user_ids = list(data['userID'].unique())\n",
    "\n",
    "print(len(book_ids), book_ids[:3])\n",
    "print(len(user_ids), user_ids[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ids.index('u08384938')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"../datasets/cse258/assignment1/train_interact_reformatted.csv\"\n",
    "\n",
    "reviews = open(fname, 'w')\n",
    "reviews.write('userIDX' + ',' + 'bookIDX' + ',' + 'rating'+ '\\n')\n",
    "\n",
    "i = 0\n",
    "for index, row in data.iterrows():\n",
    "    # print(row['userID'], row['bookID'], row['rating'])\n",
    "    reviews.write(str(user_ids.index(row['userID'])) + ',' \\\n",
    "                  + str(book_ids.index(row['bookID'])) + ',' \\\n",
    "                  + str(row['rating'])+ '\\n')\n",
    "reviews.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"../datasets/cse258/assignment1/user_reformatted.csv\"\n",
    "\n",
    "file = open(fname, 'w')\n",
    "file.write('userID' + ',' + 'userIDX' '\\n')\n",
    "\n",
    "i = 0\n",
    "for id in user_ids:\n",
    "    # print(row['userID'], row['bookID'], row['rating'])\n",
    "    file.write(str(user_ids.index(id)) + ',' + id + '\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"../datasets/cse258/assignment1/book_reformatted.csv\"\n",
    "\n",
    "file = open(fname, 'w')\n",
    "file.write('bookID' + ',' + 'bookIDX' '\\n')\n",
    "\n",
    "i = 0\n",
    "for id in book_ids:\n",
    "    # print(row['userID'], row['bookID'], row['rating'])\n",
    "    file.write(str(book_ids.index(id)) + ',' + id + '\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import reformatted interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Data columns (total 3 columns):\n",
      "userIDX    200000 non-null int64\n",
      "bookIDX    200000 non-null int64\n",
      "rating     200000 non-null int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 4.6 MB\n",
      "11357 7170\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../datasets/cse258/assignment1/train_interact_reformatted.csv\")\n",
    "data.info()\n",
    "data.head()\n",
    "\n",
    "n_user = len(data['userIDX'].unique())\n",
    "n_item = len(data['bookIDX'].unique())\n",
    "\n",
    "print(n_user,n_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userIDX</th>\n",
       "      <th>bookIDX</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1545</td>\n",
       "      <td>83</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10698</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2391</td>\n",
       "      <td>577</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>662</td>\n",
       "      <td>705</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7537</td>\n",
       "      <td>2993</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userIDX  bookIDX  rating\n",
       "0     1545       83       5\n",
       "1    10698       37       5\n",
       "2     2391      577       4\n",
       "3      662      705       5\n",
       "4     7537     2993       4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle the data\n",
    "shuffled_data = data.sample(frac=1).reset_index(drop=True)\n",
    "shuffled_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Training Dataset into Train and Validation Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userIDX</th>\n",
       "      <th>bookIDX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>190000.000000</td>\n",
       "      <td>190000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5000.590600</td>\n",
       "      <td>2695.520211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3168.769795</td>\n",
       "      <td>1944.855487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2244.000000</td>\n",
       "      <td>1012.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4725.000000</td>\n",
       "      <td>2341.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7597.000000</td>\n",
       "      <td>4155.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11356.000000</td>\n",
       "      <td>7169.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             userIDX        bookIDX\n",
       "count  190000.000000  190000.000000\n",
       "mean     5000.590600    2695.520211\n",
       "std      3168.769795    1944.855487\n",
       "min         0.000000       0.000000\n",
       "25%      2244.000000    1012.000000\n",
       "50%      4725.000000    2341.000000\n",
       "75%      7597.000000    4155.000000\n",
       "max     11356.000000    7169.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>190000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.896642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.214885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              rating\n",
       "count  190000.000000\n",
       "mean        3.896642\n",
       "std         1.214885\n",
       "min         0.000000\n",
       "25%         3.000000\n",
       "50%         4.000000\n",
       "75%         5.000000\n",
       "max         5.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userIDX</th>\n",
       "      <th>bookIDX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5010.046100</td>\n",
       "      <td>2706.787700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3179.043892</td>\n",
       "      <td>1936.120388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2241.750000</td>\n",
       "      <td>1045.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4741.500000</td>\n",
       "      <td>2367.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7599.000000</td>\n",
       "      <td>4164.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11355.000000</td>\n",
       "      <td>7161.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            userIDX       bookIDX\n",
       "count  10000.000000  10000.000000\n",
       "mean    5010.046100   2706.787700\n",
       "std     3179.043892   1936.120388\n",
       "min        1.000000      0.000000\n",
       "25%     2241.750000   1045.750000\n",
       "50%     4741.500000   2367.500000\n",
       "75%     7599.000000   4164.000000\n",
       "max    11355.000000   7161.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.898900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.202341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             rating\n",
       "count  10000.000000\n",
       "mean       3.898900\n",
       "std        1.202341\n",
       "min        0.000000\n",
       "25%        3.000000\n",
       "50%        4.000000\n",
       "75%        5.000000\n",
       "max        5.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split \n",
    "\n",
    "split = 190000\n",
    "\n",
    "train_x = shuffled_data.loc[:split-1, 'userIDX':'bookIDX']\n",
    "train_y = shuffled_data.loc[:split-1, 'rating':'rating']\n",
    "test_x = shuffled_data.loc[split:, 'userIDX':'bookIDX']\n",
    "test_y = shuffled_data.loc[split:, 'rating':'rating']\n",
    "\n",
    "display(train_x.describe())\n",
    "display(train_y.describe())\n",
    "display(test_x.describe())\n",
    "display(test_y.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "lr = 1e-3\n",
    "k = 1\n",
    "# New parameter for regularizing bias\n",
    "c_bias = 1e-5\n",
    "c_vector = 0.02\n",
    "batchsize = 1024\n",
    "\n",
    "cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[0] Iteration[0] Training Loss: 18315.96\n",
      "Epoch[0] Validation Loss: 18243.16 \n",
      "Epoch[0] Iteration[100] Training Loss: 12272.29\n",
      "Epoch[0] Validation Loss: 12223.60 \n",
      "Epoch[10] Iteration[0] Training Loss: 12.11\n",
      "Epoch[10] Validation Loss: 12.07 \n",
      "Epoch[10] Iteration[100] Training Loss: 8.61\n",
      "Epoch[10] Validation Loss: 8.56 \n",
      "Epoch[20] Iteration[0] Training Loss: 1.61\n",
      "Epoch[20] Validation Loss: 1.45 \n",
      "Epoch[20] Iteration[100] Training Loss: 1.58\n",
      "Epoch[20] Validation Loss: 1.45 \n",
      "Epoch[30] Iteration[0] Training Loss: 1.44\n",
      "Epoch[30] Validation Loss: 1.45 \n",
      "Epoch[30] Iteration[100] Training Loss: 1.74\n",
      "Epoch[30] Validation Loss: 1.45 \n",
      "Epoch[40] Iteration[0] Training Loss: 1.68\n",
      "Epoch[40] Validation Loss: 1.45 \n",
      "Epoch[40] Iteration[100] Training Loss: 1.46\n",
      "Epoch[40] Validation Loss: 1.45 \n",
      "Epoch[50] Iteration[0] Training Loss: 1.63\n",
      "Epoch[50] Validation Loss: 1.45 \n",
      "Epoch[50] Iteration[100] Training Loss: 1.37\n",
      "Epoch[50] Validation Loss: 1.45 \n",
      "Epoch[60] Iteration[0] Training Loss: 1.50\n",
      "Epoch[60] Validation Loss: 1.45 \n",
      "Epoch[60] Iteration[100] Training Loss: 1.43\n",
      "Epoch[60] Validation Loss: 1.45 \n",
      "Epoch[70] Iteration[0] Training Loss: 1.41\n",
      "Epoch[70] Validation Loss: 1.45 \n",
      "Epoch[70] Iteration[100] Training Loss: 1.55\n",
      "Epoch[70] Validation Loss: 1.45 \n",
      "Epoch[80] Iteration[0] Training Loss: 1.44\n",
      "Epoch[80] Validation Loss: 1.45 \n",
      "Epoch[80] Iteration[100] Training Loss: 1.58\n",
      "Epoch[80] Validation Loss: 1.45 \n",
      "Epoch[90] Iteration[0] Training Loss: 1.42\n",
      "Epoch[90] Validation Loss: 1.45 \n",
      "Epoch[90] Iteration[100] Training Loss: 1.29\n",
      "Epoch[90] Validation Loss: 1.45 \n",
      "Epoch[100] Iteration[0] Training Loss: 1.61\n",
      "Epoch[100] Validation Loss: 1.45 \n",
      "Epoch[100] Iteration[100] Training Loss: 1.50\n",
      "Epoch[100] Validation Loss: 1.45 \n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "\n",
    "# This code utilizes ignite engine's create_supervised_trainer()\n",
    "# But we need something more basic\n",
    "\n",
    "model = MF(n_user, n_item, k=k, c_vector=c_vector)\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "    \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "\n",
    "def chunks(X, Y, size):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    starts = list(range(0, len(X), size))\n",
    "    shuffle(starts)\n",
    "    for i in starts:\n",
    "        yield (X[i:i + size], Y[i:i + size])\n",
    "        \n",
    "batch_size = 1024\n",
    "losses = []\n",
    "for epoch in range(100+1):\n",
    "    \n",
    "    i = 0\n",
    "    for feature, target in chunks(np.array(train_x), np.array(train_y), batch_size):\n",
    "        # This zeros the gradients on every parameter. \n",
    "        # This is easy to miss and hard to troubleshoot.\n",
    "        optimizer.zero_grad()\n",
    "        # Convert \n",
    "        feature = Variable(torch.from_numpy(feature))\n",
    "        target = Variable(torch.from_numpy(target).type(torch.FloatTensor))\n",
    "        \n",
    "        if cuda:\n",
    "            feature = feature.cuda()\n",
    "            target = target.cuda()\n",
    "            \n",
    "        # model in training mode    \n",
    "        model.train()\n",
    "            \n",
    "        # Compute a prediction for these features\n",
    "        prediction = model.forward(feature)\n",
    "        # Compute a loss given what the true target outcome was\n",
    "        loss = model.loss(prediction, target)\n",
    "        # break\n",
    "        # Backpropagate: compute the direction / gradient every model parameter\n",
    "        # defined in your __init__ should move in in order to minimize this loss\n",
    "        # However, we're not actually changing these parameters, we're just storing\n",
    "        # how they should change.\n",
    "\n",
    "        loss.backward()\n",
    "        # Now take a step & update the model parameters. The optimizer uses the gradient at \n",
    "        # defined on every parameter in our model and nudges it in that direction.\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i%100 == 0 and epoch%10 == 0:\n",
    "            print(\"Epoch[{}] Iteration[{}] Training Loss: {:.2f}\".format(epoch, i, loss.data))\n",
    "\n",
    "        # Record the loss per example\n",
    "        losses.append(loss.cpu().data.numpy() / len(feature))\n",
    "        \n",
    "        if i%100 == 0 and epoch%10 == 0:\n",
    "            val_feature = torch.from_numpy(np.array(test_x))\n",
    "            val_target = torch.from_numpy(np.array(test_y)).type(torch.FloatTensor)\n",
    "            \n",
    "            if cuda:\n",
    "                val_feature = val_feature.cuda()\n",
    "                val_target = val_target.cuda()\n",
    "                \n",
    "            # model in test mode    \n",
    "            model.eval()\n",
    "\n",
    "            val_pred = model.forward(val_feature)\n",
    "            val_loss = model.loss(val_pred, val_target)\n",
    "            print(\"Epoch[{}] Validation Loss: {:.2f} \".format(epoch, val_loss.data))\n",
    "\n",
    "        i += 1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11357"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.8964])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cpu().bias.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4454, grad_fn=<ThAddBackward>)\n"
     ]
    }
   ],
   "source": [
    "feature = torch.from_numpy(np.array(test_x))\n",
    "target = torch.from_numpy(np.array(test_y)).type(torch.FloatTensor)\n",
    "\n",
    "prediction = model.forward(feature)\n",
    "loss = model.loss(prediction, target)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 3., 1.,  ..., 4., 5., 3.], device='cuda:0')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1 Kaggle Submission \n",
    "### Lambda=1.2e-5,  MSE=1.143, User_Name='Luke Liem'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
